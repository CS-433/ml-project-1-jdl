{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "import zipfile\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "zf = zipfile.ZipFile('../data/test.csv.zip')\n",
    "zf.extract('test.csv', path='../data')\n",
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "y_test, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 250000 data points and 30 features.\n",
      "There are 1580052 missing values for a total number of 7500000 values.\n"
     ]
    }
   ],
   "source": [
    "print('There are {a} data points and {b} features.'.format(a=tX.shape[0], b=tX.shape[1]))\n",
    "miss_values = len(tX[tX==-999])\n",
    "print('There are {a} missing values for a total number of {b} values.'.format(a=miss_values, b=tX.shape[0]*tX.shape[1]))\n",
    "#to continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import*\n",
    "train_tx, train_y, val_tx, val_y, test_tx, test_y = preprocessing(tX, y, tX_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters definition for all the cross validations and spliting of the data in k (=?) folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cross_validation import*\n",
    "\n",
    "seed = 1\n",
    "k_fold = 5\n",
    "\n",
    "max_iters = [50, 100, 150, 200]\n",
    "gammas = np.logspace(-4, 0, 30)\n",
    "lambdas = np.logspace(-4, 0, 30)\n",
    "\n",
    "# split data in k fold\n",
    "k_indices = build_k_indices(train_y, k_fold, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lists to store the loss of training data and test data\n",
    "rmse_tr = np.zeros((len(max_iters), len(gammas)))\n",
    "rmse_te = np.zeros((len(max_iters), len(gammas)))\n",
    "acc_tr = np.zeros((len(max_iters), len(gammas)))\n",
    "acc_te = np.zeros((len(max_iters), len(gammas)))\n",
    "# compute loss for each lambda is lambdas\n",
    "for i, max_iter in enumerate(max_iters):\n",
    "    for j, gamma in enumerate(gammas):\n",
    "        rmse_tr_tmp = []\n",
    "        rmse_te_tmp = []\n",
    "        acc_tr_tmp = []\n",
    "        acc_te_tmp = []\n",
    "        for k in range(k_fold):\n",
    "            loss_tr, loss_te, accuracy = cv_GD(train_y, train_tx, k_indices, k, max_iter, gamma)\n",
    "            rmse_tr_tmp.append(loss_tr)\n",
    "            rmse_te_tmp.append(loss_te)\n",
    "            acc_tr_tmp.append(accuracy[0])\n",
    "            acc_te_tmp.append(accuracy[1])\n",
    "            \n",
    "\n",
    "        rmse_tr[i, j] = np.mean(rmse_tr_tmp)\n",
    "        rmse_te[i, j] = np.mean(rmse_te_tmp)\n",
    "        acc_tr[i, j] = np.mean(acc_tr_tmp)\n",
    "        acc_te[i, j] = np.mean(acc_te_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum train rmse: 0.8252323228470028. max_iter = 200, gamma = 0.2807216203941176. \n",
      "minimum test rmse: 0.8252297451807662. max_iter = 200, gamma = 0.2807216203941176. \n",
      "maximum train accuracy: 0.7441314285714287. max_iter = 200, gamma = 0.2807216203941176. \n",
      "maximum test accuracy: 0.7441314285714287. max_iter = 200, gamma = 0.2807216203941176. \n"
     ]
    }
   ],
   "source": [
    "# Index of min/max error/accuracy\n",
    "i_rmse_tr = np.unravel_index(rmse_tr.argmin(), rmse_tr.shape)\n",
    "i_rmse_te = np.unravel_index(rmse_te.argmin(), rmse_te.shape)\n",
    "i_acc_tr = np.unravel_index(acc_tr.argmax(), acc_tr.shape)\n",
    "i_acc_te = np.unravel_index(acc_te.argmax(), acc_te.shape)\n",
    "\n",
    "# Values of min/max error/accuracy\n",
    "rmse_tr_min = rmse_tr[i_rmse_tr[0], i_rmse_tr[1]]\n",
    "rmse_te_min = rmse_te[i_rmse_te[0], i_rmse_te[1]]\n",
    "acc_tr_max = acc_tr[i_acc_tr[0], i_acc_tr[1]]\n",
    "acc_te_max = acc_te[i_acc_te[0], i_acc_te[1]]\n",
    "\n",
    "# Print results\n",
    "print('minimum train rmse: {rmse_tr_min}. max_iter = {max_i}, gamma = {g}. ' \n",
    "      .format(rmse_tr_min = rmse_tr_min, max_i = max_iters[i_rmse_tr[0]], g = gammas[i_rmse_tr[1]]))\n",
    "print('minimum test rmse: {rmse_te_min}. max_iter = {max_i}, gamma = {g}. ' \n",
    "      .format(rmse_te_min = rmse_te_min, max_i = max_iters[i_rmse_te[0]], g = gammas[i_rmse_te[1]]))\n",
    "print('maximum train accuracy: {acc_tr_max}. max_iter = {max_i}, gamma = {g}. ' \n",
    "      .format(acc_tr_max = acc_tr_max, max_i = max_iters[i_acc_tr[0]], g = gammas[i_acc_tr[1]]))\n",
    "print('maximum test accuracy: {acc_te_max}. max_iter = {max_i}, gamma = {g}. ' \n",
    "      .format(acc_te_max = acc_te_max, max_i = max_iters[i_acc_te[0]], g = gammas[i_acc_te[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lists to store the loss of training data and test data\n",
    "rmse_tr = np.zeros((len(max_iters), len(gammas)))\n",
    "rmse_te = np.zeros((len(max_iters), len(gammas)))\n",
    "acc_tr = np.zeros((len(max_iters), len(gammas)))\n",
    "acc_te = np.zeros((len(max_iters), len(gammas)))\n",
    "# compute loss for each lambda is lambdas\n",
    "for i, max_iter in enumerate(max_iters):\n",
    "    for j, gamma in enumerate(gammas):\n",
    "        rmse_tr_tmp = []\n",
    "        rmse_te_tmp = []\n",
    "        acc_tr_tmp = []\n",
    "        acc_te_tmp = []\n",
    "        for k in range(k_fold):\n",
    "            loss_tr, loss_te, accuracy = cv_SGD(train_y, train_tx, k_indices, k, max_iter, gamma)\n",
    "            rmse_tr_tmp.append(loss_tr)\n",
    "            rmse_te_tmp.append(loss_te)\n",
    "            acc_tr_tmp.append(accuracy[0])\n",
    "            acc_te_tmp.append(accuracy[1])\n",
    "            \n",
    "\n",
    "        rmse_tr[i, j] = np.mean(rmse_tr_tmp)\n",
    "        rmse_te[i, j] = np.mean(rmse_te_tmp)\n",
    "        acc_tr[i, j] = np.mean(acc_tr_tmp)\n",
    "        acc_te[i, j] = np.mean(acc_te_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum train rmse: 0.901986001541729. max_iter = 200, gamma = 0.006210169418915616. \n",
      "minimum test rmse: 0.9016239916555812. max_iter = 200, gamma = 0.006210169418915616. \n",
      "maximum train accuracy: 0.7028085714285714. max_iter = 200, gamma = 0.006210169418915616. \n",
      "maximum test accuracy: 0.7020799999999999. max_iter = 200, gamma = 0.006210169418915616. \n"
     ]
    }
   ],
   "source": [
    "# Index of min/max error/accuracy\n",
    "i_rmse_tr = np.unravel_index(rmse_tr.argmin(), rmse_tr.shape)\n",
    "i_rmse_te = np.unravel_index(rmse_te.argmin(), rmse_te.shape)\n",
    "i_acc_tr = np.unravel_index(acc_tr.argmax(), acc_tr.shape)\n",
    "i_acc_te = np.unravel_index(acc_te.argmax(), acc_te.shape)\n",
    "\n",
    "# Values of min/max error/accuracy\n",
    "rmse_tr_min = rmse_tr[i_rmse_tr[0], i_rmse_tr[1]]\n",
    "rmse_te_min = rmse_te[i_rmse_te[0], i_rmse_te[1]]\n",
    "acc_tr_max = acc_tr[i_acc_tr[0], i_acc_tr[1]]\n",
    "acc_te_max = acc_te[i_acc_te[0], i_acc_te[1]]\n",
    "\n",
    "# Print results\n",
    "print('minimum train rmse: {rmse_tr_min}. max_iter = {max_i}, gamma = {g}. ' \n",
    "      .format(rmse_tr_min = rmse_tr_min, max_i = max_iters[i_rmse_tr[0]], g = gammas[i_rmse_tr[1]]))\n",
    "print('minimum test rmse: {rmse_te_min}. max_iter = {max_i}, gamma = {g}. ' \n",
    "      .format(rmse_te_min = rmse_te_min, max_i = max_iters[i_rmse_te[0]], g = gammas[i_rmse_te[1]]))\n",
    "print('maximum train accuracy: {acc_tr_max}. max_iter = {max_i}, gamma = {g}. ' \n",
    "      .format(acc_tr_max = acc_tr_max, max_i = max_iters[i_acc_tr[0]], g = gammas[i_acc_tr[1]]))\n",
    "print('maximum test accuracy: {acc_te_max}. max_iter = {max_i}, gamma = {g}. ' \n",
    "      .format(acc_te_max = acc_te_max, max_i = max_iters[i_acc_te[0]], g = gammas[i_acc_te[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lists to store the loss of training data and test data\n",
    "rmse_tr = np.zeros(len(gammas))\n",
    "rmse_te = np.zeros(len(gammas))\n",
    "acc_tr = np.zeros(len(gammas))\n",
    "acc_te = np.zeros(len(gammas))\n",
    "# compute loss for each lambda is lambdas\n",
    "for i, lambda_ in enumerate(lambdas):\n",
    "    rmse_tr_tmp = []\n",
    "    rmse_te_tmp = []\n",
    "    acc_tr_tmp = []\n",
    "    acc_te_tmp = []\n",
    "    for k in range(k_fold):\n",
    "        loss_tr, loss_te, accuracy = cv_ridge_regression(train_y, train_tx, k_indices, k, lambda_)\n",
    "        rmse_tr_tmp.append(loss_tr)\n",
    "        rmse_te_tmp.append(loss_te)\n",
    "        acc_tr_tmp.append(accuracy[0])\n",
    "        acc_te_tmp.append(accuracy[1])\n",
    "\n",
    "\n",
    "    rmse_tr[i] = np.mean(rmse_tr_tmp)\n",
    "    rmse_te[i] = np.mean(rmse_te_tmp)\n",
    "    acc_tr[i] = np.mean(acc_tr_tmp)\n",
    "    acc_te[i] = np.mean(acc_te_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum train rmse: 0.8252125366736497. gamma = 0.0001. \n",
      "minimum test rmse: 0.8254032924957986. gamma = 0.00018873918221350977. \n",
      "maximum train accuracy: 0.7442528571428572. gamma = 0.00018873918221350977. \n",
      "maximum test accuracy: 0.74424. gamma = 0.0001. \n"
     ]
    }
   ],
   "source": [
    "# Index of min/max error/accuracy\n",
    "i_rmse_tr = rmse_tr.argmin()\n",
    "i_rmse_te = rmse_te.argmin()\n",
    "i_acc_tr = acc_tr.argmax()\n",
    "i_acc_te = acc_te.argmax()\n",
    "\n",
    "# Values of min/max error/accuracy\n",
    "rmse_tr_min = rmse_tr[i_rmse_tr]\n",
    "rmse_te_min = rmse_te[i_rmse_te]\n",
    "acc_tr_max = acc_tr[i_acc_tr]\n",
    "acc_te_max = acc_te[i_acc_te]\n",
    "\n",
    "# Print results\n",
    "print('minimum train rmse: {rmse_tr_min}. gamma = {g}. ' \n",
    "      .format(rmse_tr_min = rmse_tr_min, g = lambdas[i_rmse_tr]))\n",
    "print('minimum test rmse: {rmse_te_min}. gamma = {g}. ' \n",
    "      .format(rmse_te_min = rmse_te_min, g = lambdas[i_rmse_te]))\n",
    "print('maximum train accuracy: {acc_tr_max}. gamma = {g}. ' \n",
    "      .format(acc_tr_max = acc_tr_max, g = lambdas[i_acc_tr]))\n",
    "print('maximum test accuracy: {acc_te_max}. gamma = {g}. ' \n",
    "      .format(acc_te_max = acc_te_max, g = lambdas[i_acc_te]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lists to store the loss of training data and test data\n",
    "rmse_tr = np.zeros((len(max_iters), len(gammas)))\n",
    "rmse_te = np.zeros((len(max_iters), len(gammas)))\n",
    "acc_tr = np.zeros((len(max_iters), len(gammas)))\n",
    "acc_te = np.zeros((len(max_iters), len(gammas)))\n",
    "# compute loss for each max_iter and gamma\n",
    "for i, max_iter in enumerate(max_iters):\n",
    "    for j, gamma in enumerate(gammas):\n",
    "        rmse_tr_tmp = []\n",
    "        rmse_te_tmp = []\n",
    "        acc_tr_tmp = []\n",
    "        acc_te_tmp = []\n",
    "        for k in range(k_fold):\n",
    "            loss_tr, loss_te, accuracy = cv_logistic_regression(train_y, train_tx, k_indices, k, max_iter, gamma)\n",
    "            rmse_tr_tmp.append(loss_tr)\n",
    "            rmse_te_tmp.append(loss_te)\n",
    "            acc_tr_tmp.append(accuracy[0])\n",
    "            acc_te_tmp.append(accuracy[1])\n",
    "            \n",
    "\n",
    "        rmse_tr[i, j] = np.mean(rmse_tr_tmp)\n",
    "        rmse_te[i, j] = np.mean(rmse_te_tmp)\n",
    "        acc_tr[i, j] = np.mean(acc_tr_tmp)\n",
    "        acc_te[i, j] = np.mean(acc_te_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum train rmse: 550.5250469484163. max_iter = 50, gamma = 0.0001. \n",
      "minimum test rmse: 550.5212527567351. max_iter = 50, gamma = 0.0001. \n",
      "maximum train accuracy: 0.7138571428571427. max_iter = 50, gamma = 0.0001. \n",
      "maximum test accuracy: 0.7138571428571427. max_iter = 50, gamma = 0.0001. \n"
     ]
    }
   ],
   "source": [
    "# Index of min/max error/accuracy\n",
    "i_rmse_tr = np.unravel_index(rmse_tr.argmin(), rmse_tr.shape)\n",
    "i_rmse_te = np.unravel_index(rmse_te.argmin(), rmse_te.shape)\n",
    "i_acc_tr = np.unravel_index(acc_tr.argmax(), acc_tr.shape)\n",
    "i_acc_te = np.unravel_index(acc_te.argmax(), acc_te.shape)\n",
    "\n",
    "# Values of min/max error/accuracy\n",
    "rmse_tr_min = rmse_tr[i_rmse_tr[0], i_rmse_tr[1]]\n",
    "rmse_te_min = rmse_te[i_rmse_te[0], i_rmse_te[1]]\n",
    "acc_tr_max = acc_tr[i_acc_tr[0], i_acc_tr[1]]\n",
    "acc_te_max = acc_te[i_acc_te[0], i_acc_te[1]]\n",
    "\n",
    "# Print results\n",
    "print('minimum train rmse: {rmse_tr_min}. max_iter = {max_i}, gamma = {g}. ' \n",
    "      .format(rmse_tr_min = rmse_tr_min, max_i = max_iters[i_rmse_tr[0]], g = gammas[i_rmse_tr[1]]))\n",
    "print('minimum test rmse: {rmse_te_min}. max_iter = {max_i}, gamma = {g}. ' \n",
    "      .format(rmse_te_min = rmse_te_min, max_i = max_iters[i_rmse_te[0]], g = gammas[i_rmse_te[1]]))\n",
    "print('maximum train accuracy: {acc_tr_max}. max_iter = {max_i}, gamma = {g}. ' \n",
    "      .format(acc_tr_max = acc_tr_max, max_i = max_iters[i_acc_tr[0]], g = gammas[i_acc_tr[1]]))\n",
    "print('maximum test accuracy: {acc_te_max}. max_iter = {max_i}, gamma = {g}. ' \n",
    "      .format(acc_te_max = acc_te_max, max_i = max_iters[i_acc_te[0]], g = gammas[i_acc_te[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lists to store the loss of training data and test data\n",
    "rmse_tr = np.zeros((len(max_iters), len(gammas), len(lambdas)))\n",
    "rmse_te = np.zeros((len(max_iters), len(gammas), len(lambdas)))\n",
    "acc_tr = np.zeros((len(max_iters), len(gammas), len(lambdas)))\n",
    "acc_te = np.zeros((len(max_iters), len(gammas), len(lambdas)))\n",
    "# compute loss for each max_iter and gamma\n",
    "for i, max_iter in enumerate(max_iters):\n",
    "    for j, gamma in enumerate(gammas):\n",
    "        for k, lambda_ in enumerate(lambdas):\n",
    "            rmse_tr_tmp = []\n",
    "            rmse_te_tmp = []\n",
    "            acc_tr_tmp = []\n",
    "            acc_te_tmp = []\n",
    "            for k in range(k_fold):\n",
    "                loss_tr, loss_te, accuracy = cv_reg_logistic_regression(train_y, train_tx, k_indices, k, lambda_, max_iter, gamma)\n",
    "                rmse_tr_tmp.append(loss_tr)\n",
    "                rmse_te_tmp.append(loss_te)\n",
    "                acc_tr_tmp.append(accuracy[0])\n",
    "                acc_te_tmp.append(accuracy[1])\n",
    "\n",
    "\n",
    "            rmse_tr[i, j, k] = np.mean(rmse_tr_tmp)\n",
    "            rmse_te[i, j, k] = np.mean(rmse_te_tmp)\n",
    "            acc_tr[i, j, k] = np.mean(acc_tr_tmp)\n",
    "            acc_te[i, j, k] = np.mean(acc_te_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of min/max error/accuracy\n",
    "i_rmse_tr = np.unravel_index(rmse_tr.argmin(), rmse_tr.shape)\n",
    "i_rmse_te = np.unravel_index(rmse_te.argmin(), rmse_te.shape)\n",
    "i_acc_tr = np.unravel_index(acc_tr.argmax(), acc_tr.shape)\n",
    "i_acc_te = np.unravel_index(acc_te.argmax(), acc_te.shape)\n",
    "\n",
    "# Values of min/max error/accuracy\n",
    "rmse_tr_min = rmse_tr[i_rmse_tr[0], i_rmse_tr[1], i_rmse_tr[2]]\n",
    "rmse_te_min = rmse_te[i_rmse_te[0], i_rmse_te[1], i_rmse_te[2]]\n",
    "acc_tr_max = acc_tr[i_acc_tr[0], i_acc_tr[1], i_acc_tr[2]]\n",
    "acc_te_max = acc_te[i_acc_te[0], i_acc_te[1], i_acc_te[2]]\n",
    "\n",
    "# Print results\n",
    "print('minimum train rmse: {rmse_tr_min}. max_iter = {max_i}, gamma = {g}, lambda = {l}. ' \n",
    "      .format(rmse_tr_min = rmse_tr_min, max_i = max_iters[i_rmse_tr[0]], g = gammas[i_rmse_tr[1]], l = lambdas[i_rmse_tr[2]]))\n",
    "print('minimum test rmse: {rmse_te_min}. max_iter = {max_i}, gamma = {g}, lambda = {l}. ' \n",
    "      .format(rmse_te_min = rmse_te_min, max_i = max_iters[i_rmse_te[0]], g = gammas[i_rmse_te[1]], l = lambdas[i_rmse_te[2]]))\n",
    "print('maximum train accuracy: {acc_tr_max}. max_iter = {max_i}, gamma = {g}, lambda = {l}. ' \n",
    "      .format(acc_tr_max = acc_tr_max, max_i = max_iters[i_acc_tr[0]], g = gammas[i_acc_tr[1]], l = lambdas[i_acc_tr[2]]))\n",
    "print('maximum test accuracy: {acc_te_max}. max_iter = {max_i}, gamma = {g}, lambda = {l}. ' \n",
    "      .format(acc_te_max = acc_te_max, max_i = max_iters[i_acc_te[0]], g = gammas[i_acc_te[1]], l = lambdas[i_acc_te[2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../data/sample-submission.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

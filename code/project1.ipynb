{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "import zipfile\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "zf = zipfile.ZipFile('../data/test.csv.zip')\n",
    "zf.extract('test.csv', path='../data')\n",
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "y_test, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 250000 data points and 30 features in the training data.\n",
      "There are 1580052 missing values for a total number of 7500000 values in the training data. -> 21.06736% are missing values\n",
      "There are 3588434 missing values for a total number of 17047140 values in the test data. -> 21.050064702935508% are missing values\n"
     ]
    }
   ],
   "source": [
    "miss_values_tr = len(tX[tX==-999])\n",
    "miss_values_te = len(tX_test[tX_test==-999])\n",
    "print('There are {a} data points and {b} features in the training data.'.format(a=tX.shape[0], b=tX.shape[1]))\n",
    "print('There are {a} missing values for a total number of {b} values in the training data. -> {c}% are missing values'.format(a=miss_values_tr, b=tX.shape[0]*tX.shape[1], c = 100*miss_values_tr/(tX.shape[0]*tX.shape[1])))\n",
    "print('There are {a} missing values for a total number of {b} values in the test data. -> {c}% are missing values'.format(a=miss_values_te, b=tX_test.shape[0]*tX_test.shape[1], c = 100*miss_values_te/(tX_test.shape[0]*tX_test.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = np.sum(y)\n",
    "b = len(y) - s\n",
    "tot = len(y)\n",
    "labels =  [(b/tot)*100, (s/tot)*100]\n",
    "plt.bar(['b', 's'], labels, color = ['b', 'r'])\n",
    "plt.title(\"Distribution of the output variable [%]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import*\n",
    "train_tx, train_y, val_tx, val_y, test_tx, test_y = preprocessing(tX, y, tX_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters definition for all the cross validations and spliting of the data in k (=?) folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cross_validation import*\n",
    "\n",
    "seed = 1\n",
    "k_fold = 5\n",
    "\n",
    "max_iters = [50, 100, 150, 200]\n",
    "gammas = np.logspace(-4, 0, 30)\n",
    "lambdas = np.logspace(-4, 0, 30)\n",
    "\n",
    "# split data in k fold\n",
    "k_indices = build_k_indices(train_y, k_fold, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lists to store the loss of training data and test data\n",
    "rmse_tr = np.zeros((len(max_iters), len(gammas)))\n",
    "rmse_te = np.zeros((len(max_iters), len(gammas)))\n",
    "acc_tr = np.zeros((len(max_iters), len(gammas)))\n",
    "acc_te = np.zeros((len(max_iters), len(gammas)))\n",
    "# compute loss for each lambda is lambdas\n",
    "for i, max_iter in enumerate(max_iters):\n",
    "    for j, gamma in enumerate(gammas):\n",
    "        rmse_tr_tmp = []\n",
    "        rmse_te_tmp = []\n",
    "        acc_tr_tmp = []\n",
    "        acc_te_tmp = []\n",
    "        for k in range(k_fold):\n",
    "            loss_tr, loss_te, accuracy = cv_GD(train_y, train_tx, k_indices, k, max_iter, gamma)\n",
    "            rmse_tr_tmp.append(loss_tr)\n",
    "            rmse_te_tmp.append(loss_te)\n",
    "            acc_tr_tmp.append(accuracy[0])\n",
    "            acc_te_tmp.append(accuracy[1])\n",
    "            \n",
    "\n",
    "        rmse_tr[i, j] = np.mean(rmse_tr_tmp)\n",
    "        rmse_te[i, j] = np.mean(rmse_te_tmp)\n",
    "        acc_tr[i, j] = np.mean(acc_tr_tmp)\n",
    "        acc_te[i, j] = np.mean(acc_te_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum train rmse: 0.8252323228470028. max_iter = 200, gamma = 0.2807216203941176. \n",
      "minimum test rmse: 0.8252297451807662. max_iter = 200, gamma = 0.2807216203941176. \n",
      "maximum train accuracy: 0.7441314285714287. max_iter = 200, gamma = 0.2807216203941176. \n",
      "maximum test accuracy: 0.7441314285714287. max_iter = 200, gamma = 0.2807216203941176. \n"
     ]
    }
   ],
   "source": [
    "# Index of min/max error/accuracy\n",
    "i_rmse_tr = np.unravel_index(rmse_tr.argmin(), rmse_tr.shape)\n",
    "i_rmse_te = np.unravel_index(rmse_te.argmin(), rmse_te.shape)\n",
    "i_acc_tr = np.unravel_index(acc_tr.argmax(), acc_tr.shape)\n",
    "i_acc_te = np.unravel_index(acc_te.argmax(), acc_te.shape)\n",
    "\n",
    "# Values of min/max error/accuracy\n",
    "rmse_tr_min = rmse_tr[i_rmse_tr[0], i_rmse_tr[1]]\n",
    "rmse_te_min = rmse_te[i_rmse_te[0], i_rmse_te[1]]\n",
    "acc_tr_max = acc_tr[i_acc_tr[0], i_acc_tr[1]]\n",
    "acc_te_max = acc_te[i_acc_te[0], i_acc_te[1]]\n",
    "\n",
    "# Print results\n",
    "print('minimum train rmse: {rmse_tr_min}. max_iter = {max_i}, gamma = {g}. ' \n",
    "      .format(rmse_tr_min = rmse_tr_min, max_i = max_iters[i_rmse_tr[0]], g = gammas[i_rmse_tr[1]]))\n",
    "print('minimum test rmse: {rmse_te_min}. max_iter = {max_i}, gamma = {g}. ' \n",
    "      .format(rmse_te_min = rmse_te_min, max_i = max_iters[i_rmse_te[0]], g = gammas[i_rmse_te[1]]))\n",
    "print('maximum train accuracy: {acc_tr_max}. max_iter = {max_i}, gamma = {g}. ' \n",
    "      .format(acc_tr_max = acc_tr_max, max_i = max_iters[i_acc_tr[0]], g = gammas[i_acc_tr[1]]))\n",
    "print('maximum test accuracy: {acc_te_max}. max_iter = {max_i}, gamma = {g}. ' \n",
    "      .format(acc_te_max = acc_te_max, max_i = max_iters[i_acc_te[0]], g = gammas[i_acc_te[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lists to store the loss of training data and test data\n",
    "rmse_tr = np.zeros((len(max_iters), len(gammas)))\n",
    "rmse_te = np.zeros((len(max_iters), len(gammas)))\n",
    "acc_tr = np.zeros((len(max_iters), len(gammas)))\n",
    "acc_te = np.zeros((len(max_iters), len(gammas)))\n",
    "# compute loss for each lambda is lambdas\n",
    "for i, max_iter in enumerate(max_iters):\n",
    "    for j, gamma in enumerate(gammas):\n",
    "        rmse_tr_tmp = []\n",
    "        rmse_te_tmp = []\n",
    "        acc_tr_tmp = []\n",
    "        acc_te_tmp = []\n",
    "        for k in range(k_fold):\n",
    "            loss_tr, loss_te, accuracy = cv_SGD(train_y, train_tx, k_indices, k, max_iter, gamma)\n",
    "            rmse_tr_tmp.append(loss_tr)\n",
    "            rmse_te_tmp.append(loss_te)\n",
    "            acc_tr_tmp.append(accuracy[0])\n",
    "            acc_te_tmp.append(accuracy[1])\n",
    "            \n",
    "\n",
    "        rmse_tr[i, j] = np.mean(rmse_tr_tmp)\n",
    "        rmse_te[i, j] = np.mean(rmse_te_tmp)\n",
    "        acc_tr[i, j] = np.mean(acc_tr_tmp)\n",
    "        acc_te[i, j] = np.mean(acc_te_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum train rmse: 0.901986001541729. max_iter = 200, gamma = 0.006210169418915616. \n",
      "minimum test rmse: 0.9016239916555812. max_iter = 200, gamma = 0.006210169418915616. \n",
      "maximum train accuracy: 0.7028085714285714. max_iter = 200, gamma = 0.006210169418915616. \n",
      "maximum test accuracy: 0.7020799999999999. max_iter = 200, gamma = 0.006210169418915616. \n"
     ]
    }
   ],
   "source": [
    "# Index of min/max error/accuracy\n",
    "i_rmse_tr = np.unravel_index(rmse_tr.argmin(), rmse_tr.shape)\n",
    "i_rmse_te = np.unravel_index(rmse_te.argmin(), rmse_te.shape)\n",
    "i_acc_tr = np.unravel_index(acc_tr.argmax(), acc_tr.shape)\n",
    "i_acc_te = np.unravel_index(acc_te.argmax(), acc_te.shape)\n",
    "\n",
    "# Values of min/max error/accuracy\n",
    "rmse_tr_min = rmse_tr[i_rmse_tr[0], i_rmse_tr[1]]\n",
    "rmse_te_min = rmse_te[i_rmse_te[0], i_rmse_te[1]]\n",
    "acc_tr_max = acc_tr[i_acc_tr[0], i_acc_tr[1]]\n",
    "acc_te_max = acc_te[i_acc_te[0], i_acc_te[1]]\n",
    "\n",
    "# Print results\n",
    "print('minimum train rmse: {rmse_tr_min}. max_iter = {max_i}, gamma = {g}. ' \n",
    "      .format(rmse_tr_min = rmse_tr_min, max_i = max_iters[i_rmse_tr[0]], g = gammas[i_rmse_tr[1]]))\n",
    "print('minimum test rmse: {rmse_te_min}. max_iter = {max_i}, gamma = {g}. ' \n",
    "      .format(rmse_te_min = rmse_te_min, max_i = max_iters[i_rmse_te[0]], g = gammas[i_rmse_te[1]]))\n",
    "print('maximum train accuracy: {acc_tr_max}. max_iter = {max_i}, gamma = {g}. ' \n",
    "      .format(acc_tr_max = acc_tr_max, max_i = max_iters[i_acc_tr[0]], g = gammas[i_acc_tr[1]]))\n",
    "print('maximum test accuracy: {acc_te_max}. max_iter = {max_i}, gamma = {g}. ' \n",
    "      .format(acc_te_max = acc_te_max, max_i = max_iters[i_acc_te[0]], g = gammas[i_acc_te[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lists to store the loss of training data and test data\n",
    "rmse_tr = np.zeros(len(gammas))\n",
    "rmse_te = np.zeros(len(gammas))\n",
    "acc_tr = np.zeros(len(gammas))\n",
    "acc_te = np.zeros(len(gammas))\n",
    "# compute loss for each lambda is lambdas\n",
    "for i, lambda_ in enumerate(lambdas):\n",
    "    rmse_tr_tmp = []\n",
    "    rmse_te_tmp = []\n",
    "    acc_tr_tmp = []\n",
    "    acc_te_tmp = []\n",
    "    for k in range(k_fold):\n",
    "        loss_tr, loss_te, accuracy = cv_ridge_regression(train_y, train_tx, k_indices, k, lambda_)\n",
    "        rmse_tr_tmp.append(loss_tr)\n",
    "        rmse_te_tmp.append(loss_te)\n",
    "        acc_tr_tmp.append(accuracy[0])\n",
    "        acc_te_tmp.append(accuracy[1])\n",
    "\n",
    "\n",
    "    rmse_tr[i] = np.mean(rmse_tr_tmp)\n",
    "    rmse_te[i] = np.mean(rmse_te_tmp)\n",
    "    acc_tr[i] = np.mean(acc_tr_tmp)\n",
    "    acc_te[i] = np.mean(acc_te_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum train rmse: 0.8252125366736497. gamma = 0.0001. \n",
      "minimum test rmse: 0.8254032924957986. gamma = 0.00018873918221350977. \n",
      "maximum train accuracy: 0.7442528571428572. gamma = 0.00018873918221350977. \n",
      "maximum test accuracy: 0.74424. gamma = 0.0001. \n"
     ]
    }
   ],
   "source": [
    "# Index of min/max error/accuracy\n",
    "i_rmse_tr = rmse_tr.argmin()\n",
    "i_rmse_te = rmse_te.argmin()\n",
    "i_acc_tr = acc_tr.argmax()\n",
    "i_acc_te = acc_te.argmax()\n",
    "\n",
    "# Values of min/max error/accuracy\n",
    "rmse_tr_min = rmse_tr[i_rmse_tr]\n",
    "rmse_te_min = rmse_te[i_rmse_te]\n",
    "acc_tr_max = acc_tr[i_acc_tr]\n",
    "acc_te_max = acc_te[i_acc_te]\n",
    "\n",
    "# Print results\n",
    "print('minimum train rmse: {rmse_tr_min}. gamma = {g}. ' \n",
    "      .format(rmse_tr_min = rmse_tr_min, g = lambdas[i_rmse_tr]))\n",
    "print('minimum test rmse: {rmse_te_min}. gamma = {g}. ' \n",
    "      .format(rmse_te_min = rmse_te_min, g = lambdas[i_rmse_te]))\n",
    "print('maximum train accuracy: {acc_tr_max}. gamma = {g}. ' \n",
    "      .format(acc_tr_max = acc_tr_max, g = lambdas[i_acc_tr]))\n",
    "print('maximum test accuracy: {acc_te_max}. gamma = {g}. ' \n",
    "      .format(acc_te_max = acc_te_max, g = lambdas[i_acc_te]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lists to store the loss of training data and test data\n",
    "rmse_tr = np.zeros((len(max_iters), len(gammas)))\n",
    "rmse_te = np.zeros((len(max_iters), len(gammas)))\n",
    "acc_tr = np.zeros((len(max_iters), len(gammas)))\n",
    "acc_te = np.zeros((len(max_iters), len(gammas)))\n",
    "# compute loss for each max_iter and gamma\n",
    "for i, max_iter in enumerate(max_iters):\n",
    "    for j, gamma in enumerate(gammas):\n",
    "        rmse_tr_tmp = []\n",
    "        rmse_te_tmp = []\n",
    "        acc_tr_tmp = []\n",
    "        acc_te_tmp = []\n",
    "        for k in range(k_fold):\n",
    "            loss_tr, loss_te, accuracy = cv_logistic_regression(train_y, train_tx, k_indices, k, max_iter, gamma)\n",
    "            rmse_tr_tmp.append(loss_tr)\n",
    "            rmse_te_tmp.append(loss_te)\n",
    "            acc_tr_tmp.append(accuracy[0])\n",
    "            acc_te_tmp.append(accuracy[1])\n",
    "            \n",
    "\n",
    "        rmse_tr[i, j] = np.mean(rmse_tr_tmp)\n",
    "        rmse_te[i, j] = np.mean(rmse_te_tmp)\n",
    "        acc_tr[i, j] = np.mean(acc_tr_tmp)\n",
    "        acc_te[i, j] = np.mean(acc_te_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum train rmse: 550.5250469484163. max_iter = 50, gamma = 0.0001. \n",
      "minimum test rmse: 550.5212527567351. max_iter = 50, gamma = 0.0001. \n",
      "maximum train accuracy: 0.7138571428571427. max_iter = 50, gamma = 0.0001. \n",
      "maximum test accuracy: 0.7138571428571427. max_iter = 50, gamma = 0.0001. \n"
     ]
    }
   ],
   "source": [
    "# Index of min/max error/accuracy\n",
    "i_rmse_tr = np.unravel_index(rmse_tr.argmin(), rmse_tr.shape)\n",
    "i_rmse_te = np.unravel_index(rmse_te.argmin(), rmse_te.shape)\n",
    "i_acc_tr = np.unravel_index(acc_tr.argmax(), acc_tr.shape)\n",
    "i_acc_te = np.unravel_index(acc_te.argmax(), acc_te.shape)\n",
    "\n",
    "# Values of min/max error/accuracy\n",
    "rmse_tr_min = rmse_tr[i_rmse_tr[0], i_rmse_tr[1]]\n",
    "rmse_te_min = rmse_te[i_rmse_te[0], i_rmse_te[1]]\n",
    "acc_tr_max = acc_tr[i_acc_tr[0], i_acc_tr[1]]\n",
    "acc_te_max = acc_te[i_acc_te[0], i_acc_te[1]]\n",
    "\n",
    "# Print results\n",
    "print('minimum train rmse: {rmse_tr_min}. max_iter = {max_i}, gamma = {g}. ' \n",
    "      .format(rmse_tr_min = rmse_tr_min, max_i = max_iters[i_rmse_tr[0]], g = gammas[i_rmse_tr[1]]))\n",
    "print('minimum test rmse: {rmse_te_min}. max_iter = {max_i}, gamma = {g}. ' \n",
    "      .format(rmse_te_min = rmse_te_min, max_i = max_iters[i_rmse_te[0]], g = gammas[i_rmse_te[1]]))\n",
    "print('maximum train accuracy: {acc_tr_max}. max_iter = {max_i}, gamma = {g}. ' \n",
    "      .format(acc_tr_max = acc_tr_max, max_i = max_iters[i_acc_tr[0]], g = gammas[i_acc_tr[1]]))\n",
    "print('maximum test accuracy: {acc_te_max}. max_iter = {max_i}, gamma = {g}. ' \n",
    "      .format(acc_te_max = acc_te_max, max_i = max_iters[i_acc_te[0]], g = gammas[i_acc_te[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lists to store the loss of training data and test data\n",
    "rmse_tr = np.zeros((len(max_iters), len(gammas), len(lambdas)))\n",
    "rmse_te = np.zeros((len(max_iters), len(gammas), len(lambdas)))\n",
    "acc_tr = np.zeros((len(max_iters), len(gammas), len(lambdas)))\n",
    "acc_te = np.zeros((len(max_iters), len(gammas), len(lambdas)))\n",
    "# compute loss for each max_iter and gamma\n",
    "for i, max_iter in enumerate(max_iters):\n",
    "    for j, gamma in enumerate(gammas):\n",
    "        for k, lambda_ in enumerate(lambdas):\n",
    "            rmse_tr_tmp = []\n",
    "            rmse_te_tmp = []\n",
    "            acc_tr_tmp = []\n",
    "            acc_te_tmp = []\n",
    "            for k in range(k_fold):\n",
    "                loss_tr, loss_te, accuracy = cv_reg_logistic_regression(train_y, train_tx, k_indices, k, lambda_, max_iter, gamma)\n",
    "                rmse_tr_tmp.append(loss_tr)\n",
    "                rmse_te_tmp.append(loss_te)\n",
    "                acc_tr_tmp.append(accuracy[0])\n",
    "                acc_te_tmp.append(accuracy[1])\n",
    "\n",
    "\n",
    "            rmse_tr[i, j, k] = np.mean(rmse_tr_tmp)\n",
    "            rmse_te[i, j, k] = np.mean(rmse_te_tmp)\n",
    "            acc_tr[i, j, k] = np.mean(acc_tr_tmp)\n",
    "            acc_te[i, j, k] = np.mean(acc_te_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of min/max error/accuracy\n",
    "i_rmse_tr = np.unravel_index(rmse_tr.argmin(), rmse_tr.shape)\n",
    "i_rmse_te = np.unravel_index(rmse_te.argmin(), rmse_te.shape)\n",
    "i_acc_tr = np.unravel_index(acc_tr.argmax(), acc_tr.shape)\n",
    "i_acc_te = np.unravel_index(acc_te.argmax(), acc_te.shape)\n",
    "\n",
    "# Values of min/max error/accuracy\n",
    "rmse_tr_min = rmse_tr[i_rmse_tr[0], i_rmse_tr[1], i_rmse_tr[2]]\n",
    "rmse_te_min = rmse_te[i_rmse_te[0], i_rmse_te[1], i_rmse_te[2]]\n",
    "acc_tr_max = acc_tr[i_acc_tr[0], i_acc_tr[1], i_acc_tr[2]]\n",
    "acc_te_max = acc_te[i_acc_te[0], i_acc_te[1], i_acc_te[2]]\n",
    "\n",
    "# Print results\n",
    "print('minimum train rmse: {rmse_tr_min}. max_iter = {max_i}, gamma = {g}, lambda = {l}. ' \n",
    "      .format(rmse_tr_min = rmse_tr_min, max_i = max_iters[i_rmse_tr[0]], g = gammas[i_rmse_tr[1]], l = lambdas[i_rmse_tr[2]]))\n",
    "print('minimum test rmse: {rmse_te_min}. max_iter = {max_i}, gamma = {g}, lambda = {l}. ' \n",
    "      .format(rmse_te_min = rmse_te_min, max_i = max_iters[i_rmse_te[0]], g = gammas[i_rmse_te[1]], l = lambdas[i_rmse_te[2]]))\n",
    "print('maximum train accuracy: {acc_tr_max}. max_iter = {max_i}, gamma = {g}, lambda = {l}. ' \n",
    "      .format(acc_tr_max = acc_tr_max, max_i = max_iters[i_acc_tr[0]], g = gammas[i_acc_tr[1]], l = lambdas[i_acc_tr[2]]))\n",
    "print('maximum test accuracy: {acc_te_max}. max_iter = {max_i}, gamma = {g}, lambda = {l}. ' \n",
    "      .format(acc_te_max = acc_te_max, max_i = max_iters[i_acc_te[0]], g = gammas[i_acc_te[1]], l = lambdas[i_acc_te[2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../data/sample-submission.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
